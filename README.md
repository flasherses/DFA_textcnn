# 敏感内容识别模型
该项目是一个敏感内容识别模型，用于识别文本中的敏感内容。以下是代码的详细说明以及如何使用该模型。

## 数据准备
### 读取命中数据和非命中数据
命中数据存储在文件 cleaned_censor_hit.csv 中，其中包含已知的敏感内容。

非命中数据存储在文件 cleaned_comment_tb.csv 中，其中包含一般的帖子数据。
### 读取手动标记的敏感内容数据
从文件 人工删除.csv 中读取数据，该文件包含人工标记的敏感内容。
### 读取敏感词数据
从三个不同的文本文件中读取敏感词列表：
- 敏感词1.txt
- 敏感词2.txt
- 敏感词3.txt

敏感词文件中每行包含一个敏感词，这些词将被标记为敏感内容，为了方便处理，这些词都会被赋予标签1。

###  数据合并
将所有读取的数据进行合并，形成一个总的数据集 data。

合并过程包括将命中数据、非命中数据、人工标记的敏感内容以及从文本文件中读取的敏感词数据合并为一个数据集。

## 数据预处理
对每个文本数据进行中文分词处理，使用结巴分词库进行分词操作。

过滤掉分词后长度小于4的文本，太短的文本不进行分词。过滤掉大于60的长度文本，太长的文本并不适合训练。

移除停用词，将每个文本中的常见无意义词语过滤掉，以减少特征空间和噪声影响。

## 特征提取
使用fasttext 词向量预训练取权重提取特征。如果词不在预训练的词向量中，使用相近词向量代替

使用Tokenizer()方法对训练集文本进行拟合和转换，建立词汇表

使用tokenizer.texts_to_sequences方法对测试集文本进行转换，确保训练集和测试集使用相同的词汇表和特征维度。

最后，得到的TF-IDF特征矩阵将作为机器学习模型的输入，用于训练和预测。

## 模型训练
模型训练在train.py这个文件中完成

使用 train_test_split 函数从整体数据中分割出训练集和测试集，通常采用80%的数据作为训练集，20%的数据作为测试集。

使用textcnn模型进行训练,使用早停技术，并保存验证集损失函数最低的模型

训练好的模型使用 tensorflow sava保存为文件，以便后续使用。

## 模型评估
使用测试集对训练好的模型进行评估，主要评估指标包括准确率和生成的分类报告。

### 计算准确率：
- 准确率是模型正确预测的样本数量与总样本数量之比。它是最简单直观的评估指标之一，表示模型在所有样本中预测正确的比例。

###  生成分类报告

- 精确度（Precision）衡量了模型在预测为正类别时的准确性。
- 召回率（Recall）衡量了模型对正类别样本的识别能力。
- F1分数是精确度和召回率的调和平均值，综合考虑了二者。
- 支持度（Support）是指在测试集中每个类别的样本数量。
### 结果展示
打印出模型的准确率以及生成的分类报告，以便更详细地了解模型在测试集上的性能表现。

准确率越高，表示模型在测试集上的性能越好。分类报告可以了解模型对每个类别的预测表现，以及模型的整体性能。
。
## 文件说明
- cleaned_censor_hit.csv：命中数据文件。
- cleaned_comment_tb.csv：非命中数据文件。
- 人工删除.csv：手动删除的敏感内容文件。
- 敏感词1.txt、敏感词2.txt、敏感词3.txt：敏感词文本文件。
- chinese_stopwords.txt：中文停用词文件。
- cc.zh.300.bin 预训练的词向量模型
- tokenizer.pkl：- fasttext_textcnn.h5：训练好的敏感内容识别模型文件。

# 敏感内容监测系统

该系统是一个用于监测论坛评论和帖子内容是否包含敏感信息的工具。以下是系统的功能和实现细节：

## 功能特点：

1. **敏感内容监测**：
   - 通过加载模型，系统能够检测文本中是否包含敏感内容。
   - 敏感内容包括但不限于敏感词汇、涉及敏感主题的内容等。

2. **敏感内容报警**：
   - 当系统检测到敏感内容时，会发送Markdown格式的消息到指定的企业微信群。
   - 报警信息包含帖子内容、敏感度评分以及检测到的敏感词汇。

3. **文本处理**：
   - 对帖子内容进行文本处理，包括中文分词、去除停用词等预处理步骤。
   - 使用jieba进行中文分词，去除HTML标签，过滤特殊字符等。

### 实现细节：

1. **数据库连接配置**：
   - 使用pymysql库配置数据库连接信息，包括主机地址、用户名、密码、数据库名称等。
   - 确保数据库用户具有读取论坛评论和帖子内容的权限。
   
2. **模型加载和预处理**：

   - 使用joblib库加载预训练的模型和向量化器，用于文本分类和特征提取。
   - 对帖子内容进行预处理，包括去除HTML标签、特殊字符，使用jieba进行中文分词，去除停用词等。
   
3. **消息发送到企业微信**：

   - 通过企业微信的Webhook功能，实现消息的发送到指定群组。
   - 构建消息内容为Markdown格式，包括帖子内容、敏感度评分以及检测到的敏感词汇。
   
4. **敏感内容检测**：

   - 使用加载的模型对处理后的帖子内容进行分类，判断是否为敏感内容。
   - 对长文本进行滑动切割，切割后逐个进行预测。
   - 设定敏感度阈值，如0.5，超过该阈值则判断为敏感内容。
   - 若为敏感内容，则进一步检查其中是否包含敏感词汇，以提供更详细的报警信息。
   
5. **定时扫描数据库**：

   - 使用time库定时扫描数据库，持续监测最新的帖子内容。
   - 通过记录已扫描的帖子ID，避免重复扫描，提高效率。
   - 设置合理的扫描间隔，如每隔几分钟进行一次扫描，以及在无新数据时进行等待。

### 使用方法：

1. 配置数据库连接信息和企业微信Webhook地址。
2. 启动系统，即可开始监测论坛评论和帖子内容。
3. 在企业微信群中即时收到敏感内容的报警信息，可及时处理。

通过该系统，论坛管理者可以更加有效地监控和管理用户发布的内容，维护论坛的良好环境。

2024.07.03
# 新增优化点：
## 1. 使用DFA算法进行敏感词检测，如果DFA检测出敏感词，就直接返回，如果没有检测出，再使用textcnn进行预测
## 2. 更新正则表达式，优化对传入数据的处理
## 3. 使用flask对模型预测进行封装，通过get/post请求，能返回更详细的预测结果
### 3.1 使用get请求
   - 请求参数：http://10.12.35.100:5000/predict?text="我一次出法宝秒180万，加宠物50万，一小时打了几次，打到150回合开眼怪还满血呢"
   - 输出：敏感词检测结果
### 3.2 使用post请求
   - 请求参数：http://10.12.35.100:5000/predict
   - 请求体：{"text":"我一次出法宝秒180万，加宠物50万，一小时打了几次，打到150回合开眼怪还满血呢"}
   - 输出：敏感词检测结果
